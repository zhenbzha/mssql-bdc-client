{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<img src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n",
                "<br>\r\n",
                "\r\n",
                "# SQL Server 2019 big data cluster Tutorial\r\n",
                "## 03 - Creating and Querying a Data Mart\r\n",
                "\r\n",
                "In this tutorial you will learn how to create and query a Data Mart using Virtualized Data in a SQL Server big data cluster. \r\n",
                "\r\n",
                "Wide World Importers is interested in ingesting the data from web logs from an HDFS source where they have been streamed. They want to be able to analyze the traffic to see if there is a pattern in time, products or locations. \r\n",
                "\r\n",
                "The web logs, however, are refreshed periodically. WWI would like to keep the logs in local storage to do deeper analysis. \r\n",
                "\r\n",
                "In this Jupyter Notebook you'll create a location to store the log files as a SQL Server Table in the SQL Data Pool, and then fill it by creating an External Table that reads HDFS."
            ],
            "metadata": {
                "azdata_cell_guid": "14f29fab-5ec8-48c8-aa9e-b222a1b4711e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "IF NOT EXISTS\r\n",
                "(\r\n",
                "  SELECT 1\r\n",
                "  FROM sys.external_data_sources\r\n",
                "  WHERE\r\n",
                "    name = 'SqlDataPool'\r\n",
                ")\r\n",
                "BEGIN\r\n",
                "  CREATE EXTERNAL DATA SOURCE SqlDataPool\r\n",
                "  WITH (LOCATION = 'sqldatapool://controller-svc/default');\r\n",
                "END"
            ],
            "metadata": {
                "azdata_cell_guid": "50e34d0b-d28e-4145-bfd4-0bf9a6ca9f3a"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "IF NOT EXISTS\r\n",
                "(\r\n",
                "    SELECT 1\r\n",
                "    FROM sys.external_tables\r\n",
                "    WHERE\r\n",
                "        name = N'web_clickstream_clicks_data_pool'\r\n",
                ")\r\n",
                "BEGIN\r\n",
                "    CREATE EXTERNAL TABLE dbo.web_clickstream_clicks_data_pool\r\n",
                "    (\r\n",
                "        wcs_click_date_sk BIGINT,\r\n",
                "        wcs_click_time_sk BIGINT,\r\n",
                "        wcs_sales_sk BIGINT,\r\n",
                "        wcs_item_sk BIGINT,\r\n",
                "        wcs_web_page_sk BIGINT,\r\n",
                "        wcs_user_sk BIGINT\r\n",
                "    )\r\n",
                "    WITH\r\n",
                "    (\r\n",
                "        DATA_SOURCE = SqlDataPool,\r\n",
                "        DISTRIBUTION = ROUND_ROBIN\r\n",
                "    );\r\n",
                "END\r\n",
                "GO"
            ],
            "metadata": {
                "azdata_cell_guid": "961832c4-c12b-40cd-b239-1389965fe1b0"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "IF NOT EXISTS\r\n",
                "(\r\n",
                "    SELECT 1\r\n",
                "    FROM sys.external_file_formats\r\n",
                "    WHERE\r\n",
                "        name = N'csv_file'\r\n",
                ")\r\n",
                "BEGIN\r\n",
                "    CREATE EXTERNAL FILE FORMAT csv_file\r\n",
                "    WITH\r\n",
                "    (\r\n",
                "        FORMAT_TYPE = DELIMITEDTEXT,\r\n",
                "        FORMAT_OPTIONS\r\n",
                "        (\r\n",
                "            FIELD_TERMINATOR = ',',\r\n",
                "            STRING_DELIMITER = '\"',\r\n",
                "            FIRST_ROW = 2, \r\n",
                "            USE_TYPE_DEFAULT = True\r\n",
                "        )\r\n",
                "    )\r\n",
                "END\r\n",
                "GO\r\n",
                "\r\n",
                "/* Create an External Table that can read from the Storage Pool File Location */\r\n",
                "IF NOT EXISTS\r\n",
                "(\r\n",
                "    SELECT 1\r\n",
                "    FROM sys.external_tables\r\n",
                "    WHERE\r\n",
                "        name = 'web_clickstreams_hdfs'\r\n",
                ")\r\n",
                "BEGIN\r\n",
                "    CREATE EXTERNAL TABLE dbo.web_clickstreams_hdfs\r\n",
                "    (\r\n",
                "        wcs_click_date_sk BIGINT,\r\n",
                "        wcs_click_time_sk BIGINT,\r\n",
                "        wcs_sales_sk BIGINT,\r\n",
                "        wcs_item_sk BIGINT,\r\n",
                "        wcs_web_page_sk BIGINT,\r\n",
                "        wcs_user_sk BIGINT\r\n",
                "    )\r\n",
                "    WITH\r\n",
                "    (\r\n",
                "        DATA_SOURCE = SqlStoragePool,\r\n",
                "        LOCATION = '/web_logs',\r\n",
                "        FILE_FORMAT = csv_file\r\n",
                "    );\r\n",
                "END"
            ],
            "metadata": {
                "azdata_cell_guid": "fa4f199d-88a7-4e21-bd36-5625367179fd"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "INSERT INTO dbo.web_clickstream_clicks_data_pool\r\n",
                "SELECT\r\n",
                "   hdfs.wcs_click_date_sk,\r\n",
                "   hdfs.wcs_click_time_sk,\r\n",
                "   hdfs.wcs_sales_sk,\r\n",
                "   hdfs.wcs_item_sk,\r\n",
                "   hdfs.wcs_web_page_sk,\r\n",
                "   hdfs.wcs_user_sk\r\n",
                "FROM web_clickstreams_hdfs hdfs;"
            ],
            "metadata": {
                "azdata_cell_guid": "ca7d325d-46e4-4dbc-846a-12a1d6ce351b"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": [
                "SELECT\r\n",
                "    COUNT(*) AS TotalRecords\r\n",
                "FROM [dbo].[web_clickstream_clicks_data_pool];\r\n",
                "\r\n",
                "SELECT TOP(10) *\r\n",
                "FROM [dbo].[web_clickstream_clicks_data_pool];"
            ],
            "metadata": {
                "azdata_cell_guid": "5a24d573-8a03-404a-9fb7-cd6dc9ee6787"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Next Steps: Continue on to Working with Spark and ETL\r\n",
                "\r\n",
                "Now you're ready to open the next Python Notebook - `notebook_04.ipynb` - to learn how to create and work with Spark and Extracting, Transforming and Loading data."
            ],
            "metadata": {
                "azdata_cell_guid": "fafe9af5-dba5-43f5-9425-9208477d801f"
            }
        }
    ]
}